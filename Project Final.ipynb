{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7806337,"sourceType":"datasetVersion","datasetId":4571576},{"sourceId":7821898,"sourceType":"datasetVersion","datasetId":4582956}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Movie Ratings Prediction Project\n\n## Introduction\nWelcome to the Movie Ratings Prediction Project. In this analysis, we aim to build a recommender system using collaborative filtering. The goal of our algorithm is to accurately forecast user ratings for movies they have not yet seen, leveraging their historical preferences.\n\nThe value of a well-crafted recommender system cannot be overstated. It has the potential to enhance user experience by providing personalized content, increasing user engagement, and consequently, driving revenue for streaming platforms. Our evaluation focuses on minimizing the Root Mean Square Error (RMSE) between the predicted and the actual movie ratings, offering quantifiable evidence of the recommender system's performance.","metadata":{}},{"cell_type":"markdown","source":"***Model Development***","metadata":{}},{"cell_type":"markdown","source":"## Data Exploration\nWe begin our analysis with a thorough exploration of the dataset, comprising user rating histories. We identify patterns, anomalies, and the distribution of user interactions.","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:01.255852Z","iopub.execute_input":"2024-03-12T12:36:01.256339Z","iopub.status.idle":"2024-03-12T12:36:01.263963Z","shell.execute_reply.started":"2024-03-12T12:36:01.256307Z","shell.execute_reply":"2024-03-12T12:36:01.262482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Load the dataset**\n\n## Preprocessing\nData preprocessing steps were taken to ensure the quality of the dataset. This includes handling missing values, normalizing data, and potentially feature engineering.","metadata":{}},{"cell_type":"code","source":"genome_scores_df = pd.read_csv(\"/kaggle/input/ea-movie-recommendation-predict-2023-2024/genome_scores.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:01.265990Z","iopub.execute_input":"2024-03-12T12:36:01.267309Z","iopub.status.idle":"2024-03-12T12:36:11.343283Z","shell.execute_reply.started":"2024-03-12T12:36:01.267273Z","shell.execute_reply":"2024-03-12T12:36:11.342199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"genore_tags_df = pd.read_csv(\"/kaggle/input/ea-movie-recommendation-predict-2023-2024/genome_tags.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:11.348131Z","iopub.execute_input":"2024-03-12T12:36:11.348898Z","iopub.status.idle":"2024-03-12T12:36:11.365509Z","shell.execute_reply.started":"2024-03-12T12:36:11.348854Z","shell.execute_reply":"2024-03-12T12:36:11.364521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/ea-movie-recommendation-predict-2023-2024/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:11.367347Z","iopub.execute_input":"2024-03-12T12:36:11.367868Z","iopub.status.idle":"2024-03-12T12:36:17.299870Z","shell.execute_reply.started":"2024-03-12T12:36:11.367839Z","shell.execute_reply":"2024-03-12T12:36:17.298459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/ea-movie-recommendation-predict-2023-2024/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:17.303063Z","iopub.execute_input":"2024-03-12T12:36:17.303463Z","iopub.status.idle":"2024-03-12T12:36:18.716157Z","shell.execute_reply.started":"2024-03-12T12:36:17.303432Z","shell.execute_reply":"2024-03-12T12:36:18.714862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies_df = pd.read_csv(\"/kaggle/input/ea-movie-recommendation-predict-2023-2024/movies.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:18.718492Z","iopub.execute_input":"2024-03-12T12:36:18.719446Z","iopub.status.idle":"2024-03-12T12:36:18.863433Z","shell.execute_reply.started":"2024-03-12T12:36:18.719405Z","shell.execute_reply":"2024-03-12T12:36:18.862186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tags_df = pd.read_csv(\"/kaggle/input/ea-movie-recommendation-predict-2023-2024/tags.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:18.865373Z","iopub.execute_input":"2024-03-12T12:36:18.866134Z","iopub.status.idle":"2024-03-12T12:36:20.101630Z","shell.execute_reply.started":"2024-03-12T12:36:18.866100Z","shell.execute_reply":"2024-03-12T12:36:20.100410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"links_df = pd.read_csv(\"/kaggle/input/ea-movie-recommendation-predict-2023-2024/links.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:20.103510Z","iopub.execute_input":"2024-03-12T12:36:20.103873Z","iopub.status.idle":"2024-03-12T12:36:20.154164Z","shell.execute_reply.started":"2024-03-12T12:36:20.103843Z","shell.execute_reply":"2024-03-12T12:36:20.152396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"My_submission_df = pd.read_csv(\"/kaggle/input/my-submission/my_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:20.156255Z","iopub.execute_input":"2024-03-12T12:36:20.156759Z","iopub.status.idle":"2024-03-12T12:36:26.556697Z","shell.execute_reply.started":"2024-03-12T12:36:20.156717Z","shell.execute_reply":"2024-03-12T12:36:26.555156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Display the first few rows of the training data to understand its structure**","metadata":{}},{"cell_type":"code","source":"\nprint(links_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:26.558510Z","iopub.execute_input":"2024-03-12T12:36:26.559106Z","iopub.status.idle":"2024-03-12T12:36:26.576212Z","shell.execute_reply.started":"2024-03-12T12:36:26.559070Z","shell.execute_reply":"2024-03-12T12:36:26.574280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(tags_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:26.581367Z","iopub.execute_input":"2024-03-12T12:36:26.581792Z","iopub.status.idle":"2024-03-12T12:36:26.597985Z","shell.execute_reply.started":"2024-03-12T12:36:26.581752Z","shell.execute_reply":"2024-03-12T12:36:26.596134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(movies_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:26.600734Z","iopub.execute_input":"2024-03-12T12:36:26.601361Z","iopub.status.idle":"2024-03-12T12:36:26.617688Z","shell.execute_reply.started":"2024-03-12T12:36:26.601328Z","shell.execute_reply":"2024-03-12T12:36:26.616001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:26.619561Z","iopub.execute_input":"2024-03-12T12:36:26.620045Z","iopub.status.idle":"2024-03-12T12:36:26.638424Z","shell.execute_reply.started":"2024-03-12T12:36:26.620003Z","shell.execute_reply":"2024-03-12T12:36:26.636968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(train_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:26.640482Z","iopub.execute_input":"2024-03-12T12:36:26.641191Z","iopub.status.idle":"2024-03-12T12:36:26.656682Z","shell.execute_reply.started":"2024-03-12T12:36:26.641154Z","shell.execute_reply":"2024-03-12T12:36:26.655780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(genome_scores_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:26.657663Z","iopub.execute_input":"2024-03-12T12:36:26.658147Z","iopub.status.idle":"2024-03-12T12:36:26.673218Z","shell.execute_reply.started":"2024-03-12T12:36:26.658087Z","shell.execute_reply":"2024-03-12T12:36:26.672117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(genore_tags_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:26.674551Z","iopub.execute_input":"2024-03-12T12:36:26.674870Z","iopub.status.idle":"2024-03-12T12:36:26.702379Z","shell.execute_reply.started":"2024-03-12T12:36:26.674842Z","shell.execute_reply":"2024-03-12T12:36:26.701315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n## Model Evaluation\nOur model evaluation is based on the comparison between actual ratings and the SVD model predictions. We diligently split our data into training and test sets to validate the model's predictive power.\n","metadata":{}},{"cell_type":"markdown","source":"1. Model Training:\nThis would follow the steps for setting up a collaborative filtering model with Surprise's SVD. \n\n2. Predicting Ratings:\nWe utilize the trained model to make predictions on the user-movie pairs provided in the test set.\n\n3. Preparing Submission File:\nCreating the submsission file","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom surprise import Dataset, Reader, SVD\nfrom surprise.model_selection import train_test_split\nfrom surprise import accuracy\n\n# Now, set up the reader for Surprise, which specifies the scale of your rating scores\nreader = Reader(rating_scale=(0.5, 5.0))\n\n# Load the data from the DataFrame into the Surprise data structure\ndata = Dataset.load_from_df(train_df[['userId', 'movieId', 'rating']], reader)\n\n# Instantiate the SVD algorithm from Surprise\nalgo = SVD()\n\n# Train on the full dataset\ntrainset = data.build_full_trainset()\nalgo.fit(trainset)\n\n# Load the test set\ntest_df = pd.read_csv(\"/kaggle/input/ea-movie-recommendation-predict-2023-2024/test.csv\")\n\n# Prepare the testset in the format that Surprise requires: a list of tuples (userId, movieId, rating)\n# Since we don't have the ratings for the test set, we can fill in dummy values (like the global mean)\ntestset = [(row['userId'], row['movieId'], trainset.global_mean) for index, row in test_df.iterrows()]\n\n# Obtain the predictions\npredictions = algo.test(testset)\n\n# Assuming predictions is a list of Prediction objects from the Surprise library...\nsubmission = pd.DataFrame(predictions, columns=['uid', 'iid', 'r_ui', 'est', 'details'])\n\n# Construct the 'Id' according to the competition's specifications\nsubmission['Id'] = submission['uid'].astype(str) + \"_\" + submission['iid'].astype(str)\n\n# Select the predictions (estimates) and the 'Id' for the submission file\nsubmission = submission[['Id', 'est']]\n\n# Rename the 'est' column to 'rating'\nsubmission.rename(columns={'est': 'rating'}, inplace=True)\n\n# Viewing the first few entries of the submission file\nprint(submission.head())\n\n# Save the DataFrame to a CSV file, formatted as per the submission requirements\nsubmission.to_csv('my_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:36:26.704448Z","iopub.execute_input":"2024-03-12T12:36:26.704832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Load My_submission_data **********","metadata":{}},{"cell_type":"code","source":"My_submission_df = pd.read_csv(\"/kaggle/input/my-submission/my_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(My_submission_df.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualization**\n\nFindings will be visualised on the below as follows: ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\n# Provided 'Id' and 'rating' data\nid_data = [\n    # ... (other 'Id' strings were here)\n    '3_858', '3_1198', '3_1201'\n]\nrating_data = [\n    # ... (other ratings matched with 'Id' strings were here)\n    3.9355, 4.5145, 4.3727\n]\n\n# Create a DataFrame from the data\nsubmission_df = pd.DataFrame({\n    'Id': id_data,\n    'rating': rating_data\n})\n\n# Fit K-means clustering on the 'rating' column\n# Reshaping 'rating' column to (-1, 1) because it's a single feature\nkmeans = KMeans(n_clusters=3, random_state=42)\nsubmission_df['cluster'] = kmeans.fit_predict(submission_df[['rating']].values.reshape(-1, 1))\n\n# Visualize the clusters using a scatter plot\n# Using index of the dataframe as a proxy for x-axis\nplt.figure(figsize=(12, 8))\nplt.scatter(submission_df.index, submission_df['rating'], c=submission_df['cluster'], cmap='viridis')\nplt.title('K-Means Clustering of Ratings')\nplt.xlabel('Index (as a proxy for Id)')\nplt.xticks(ticks=submission_df.index, labels=submission_df['Id'], rotation=90)  # Set x-ticks as 'Id' labels\nplt.ylabel('Rating')\nplt.colorbar(label='Cluster Label')\nplt.show()\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Provided 'Id' and 'rating' data\nid_data = [\n    '1_2011', '1_4144', '1_5767', '1_6711', '1_7318', '1_8405', '1_8786',\n    '2_150', '2_356', '2_497', '2_588', '2_653', '2_1080', '2_1196',\n    # ... (other 'Id' strings were here)\n    '3_858', '3_1198', '3_1201'\n]\nrating_data = [\n    3.7213, 4.3325, 3.9026, 4.0267, 2.6756, 3.9144, 4.1232,\n    3.7162, 3.6696, 3.4718, 3.4780, 3.2578, 3.9144, 4.5850,\n    # ... (other ratings matched with 'Id' strings were here)\n    3.9355, 4.5145, 4.3727\n]\n\n# Create a DataFrame from the data\nsubmission_df = pd.DataFrame({\n    'Id': id_data,\n    'rating': rating_data\n})\n\n# Fit K-means clustering on the 'rating' column\n# We must reshape 'rating' column to (-1, 1) because it's a single feature\nkmeans = KMeans(n_clusters=3, random_state=42)\nsubmission_df['cluster'] = kmeans.fit_predict(submission_df[['rating']])\n\n# Visualize the clusters using a scatter plot\nplt.figure(figsize=(12, 8))\nplt.scatter(submission_df['Id'], submission_df['rating'], c=submission_df['cluster'], cmap='viridis')\nplt.title('K-Means Clustering of Ratings')\nplt.xlabel('Id')\nplt.ylabel('Rating')\nplt.xticks(rotation=90)  # Rotate x-axis labels to make them readable\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**RMSE **","metadata":{}},{"cell_type":"code","source":"from surprise import Dataset, Reader, SVD\nfrom surprise.model_selection import train_test_split\nfrom surprise import accuracy\n\n# Load your training dataset\n# train_df = pd.read_csv('path_to_your_training_dataset.csv')\n\n# Create the 'reader' object to interpret the data\nreader = Reader(rating_scale=(0.5, 5.0))\n\n# Load the dataset into Surprise's format\ndata = Dataset.load_from_df(train_df[['userId', 'movieId', 'rating']], reader)\n\n# Instantiate the SVD algorithm\nalgo = SVD(verbose=True)\n\n# Split the dataset for evaluation\ntrainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n\n# Here we fit the algorithm on the trainset and evaluate it\nalgo.fit(trainset)\n\n# Make predictions on the testset\npredictions = algo.test(testset)\n\n# Calculate RMSE on the test set\nrmse = accuracy.rmse(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With these changes, the code will correctly fit the SVD algorithm on the training subset and then evaluate the predictions on the test subset using RMSE for the accuracy measure.","metadata":{}},{"cell_type":"markdown","source":"After obtaining predictions, We visualize the performance of the recommendation system, specifically the RMSE, by comparing the predicted ratings against the actual ratings from the test set.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Convert predictions to a DataFrame\npreds = pd.DataFrame([(pred.uid, pred.iid, pred.r_ui, pred.est) for pred in predictions], \n                     columns=['UserID', 'MovieID', 'Actual', 'Predicted'])\n\n# Scatter Plot\nplt.figure(figsize=(10, 6))\nplt.scatter(preds['Actual'], preds['Predicted'], alpha=0.3)\nplt.plot([0, 5], [0, 5], 'r-', linewidth=2)  # plot a thin red line for 1-1 correlation\nplt.title('Actual vs Predicted Ratings')\nplt.xlabel('Actual Rating')\nplt.ylabel('Predicted Rating')\nplt.grid(True)\nplt.show()\n\n# Distribution of Residuals (Errors)\nresiduals = preds['Actual'] - preds['Predicted']\n\nplt.figure(figsize=(10, 6))\nplt.hist(residuals, bins=30, edgecolor='black')\nplt.title('Distribution of Residuals')\nplt.xlabel('Actual - Predicted Rating')\nplt.ylabel('Frequency')\nplt.show()\n\n# RMSE Calculation for Test Set\nrmse = np.sqrt(np.mean(residuals**2))\nprint(f'Test RMSE: {rmse:.2f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In these plots:\n\nScatter Plot: It shows the actual ratings compared to the predicted ratings. If the predictions were perfect, all points would fall on the red line where the actual rating equals the predicted rating.\n\nHistogram of Residuals: It displays the distribution of errors (residuals). If the predictions are unbiased, the histogram should be centered around zero, and ideally, have a normal distribution.\n\nRemember that visualizations are not just for presentation but for insight as well. They might inform you about the nature of the errors your model makes and guide you on what to focus on to improve the model. For instance, a long tail on the left side in the histogram might suggest that the system often underestimates the actual ratings.","metadata":{}},{"cell_type":"markdown","source":"\n# Conclusion\n\n## Summary of Findings\nIn summary, our recommender system powered by Singular Vector Decomposition (SVD) has demonstrated a commendable capability in predicting user ratings for movies. With an RMSE value that quantifies our model’s predictive accuracy, we've established a solid benchmark for future enhancements. The visualizations provided key insights into the distribution of residuals and the correlation between actual and predicted ratings, underscoring the model's effectiveness and also revealing areas for improvement.\n\n## Economic Significance\nThe economic implications of deploying a functional recommender system are far-reaching. The predictive power that our system holds can facilitate a transformative shift for streaming platforms, paving the way for higher user retention, increased user engagement, and an uptick in revenue through more personalized content delivery. As such, our model's deployment can serve as a strategic tool in curating user-specific content, thereby bolstering platform affinity and fostering a sophisticated content discovery experience.\n\n## Future Work and Improvements\nWhile the current model performs admirably, in the realm of recommendation engines, there is always room for refinement. Further tuning of hyperparameters, exploring alternative collaborative filtering algorithms, or integrating content-based methods may yield even more precise recommendations. Additional feature engineering, such as incorporating temporal dynamics or social networking effects, might also enhance the system's accuracy. Furthermore, scalability concerns and cold start problems associated with new users or items warrant strategic solutions as we envision our model's application at scale.\n\n## Final Remarks\nWe are optimistic that with continual innovation and adaptation to user dynamics, recommendation systems like the one developed in this project will remain instrumental in shaping the vibrant landscape of digital media consumption. Our work is a stepping stone towards creating more intelligent, adaptive, and context-aware systems that could redefine the industry standards for content recommendation.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ndf = pd.DataFrame(\n    np.random.rand(100, 5),\n    columns=['a', 'b', 'c', 'd', 'e'])\ndf.to_csv('/kaggle/working/df.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}